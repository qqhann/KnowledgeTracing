{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T09:41:24.267450Z",
     "start_time": "2019-03-24T09:41:23.793291Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from math import log, ceil\n",
    "from typing import List, Tuple, Set, Dict\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:50:47.157706Z",
     "start_time": "2019-03-19T10:50:47.059107Z"
    }
   },
   "outputs": [],
   "source": [
    "dirname = Path().resolve()\n",
    "infname = dirname.parent / 'data/input/skill_builder_data_corrected.pickle'\n",
    "\n",
    "with open(infname, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "https://pytorch.org/docs/stable/nn.html#embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T11:09:40.002988Z",
     "start_time": "2019-03-19T11:09:39.999318Z"
    }
   },
   "outputs": [],
   "source": [
    "M = 26688+1\n",
    "N = ceil(log(2 * M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T11:10:13.200904Z",
     "start_time": "2019-03-19T11:10:13.193639Z"
    }
   },
   "outputs": [],
   "source": [
    "input = torch.LongTensor([145])\n",
    "embedding = nn.Embedding(M, N)\n",
    "e = embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T11:10:14.451930Z",
     "start_time": "2019-03-19T11:10:14.447117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5166, -0.9605,  0.2136, -0.1716,  1.2936, -0.8574,  0.4236, -0.9219,\n",
       "          0.3301,  0.3970, -0.3356]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "https://pytorch.org/docs/stable/nn.html#rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:08:21.943857Z",
     "start_time": "2019-03-20T05:08:21.883040Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn = nn.RNN(10, 20, 100)\n",
    "input = torch.randn(10, 1, 10)\n",
    "h0 = torch.randn(100, 1, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:08:23.692547Z",
     "start_time": "2019-03-20T05:08:23.687876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 20])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:15:56.273692Z",
     "start_time": "2019-03-20T05:15:56.269635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:16:11.577032Z",
     "start_time": "2019-03-20T05:16:11.572823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:16:19.532062Z",
     "start_time": "2019-03-20T05:16:19.526399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:17:50.590316Z",
     "start_time": "2019-03-20T05:17:50.580314Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.3679e-01,  9.2506e-01, -4.3670e-01, -4.8357e-01, -3.7038e-01,\n",
       "          2.3508e-01, -5.4885e-02, -8.1267e-03,  3.9844e-01,  3.4068e-01,\n",
       "         -8.7025e-02,  1.0716e-01, -4.5075e-01, -6.9968e-01, -5.0000e-01,\n",
       "         -3.3292e-01,  8.4960e-01,  2.9144e-02, -8.1647e-01,  6.1188e-01],\n",
       "        [-4.0968e-02, -4.6676e-01, -5.4840e-01, -6.3862e-01, -9.8110e-02,\n",
       "         -3.2573e-01, -5.5970e-01,  2.2142e-01, -5.2223e-01, -3.4984e-01,\n",
       "          2.1804e-01,  1.7349e-01, -5.3331e-01, -3.8534e-01,  1.3440e-01,\n",
       "         -5.1388e-01, -1.7391e-01,  1.9375e-01, -4.0908e-01,  1.4386e-01],\n",
       "        [-1.3205e-01, -2.3401e-01, -2.3190e-01, -5.1171e-01, -8.6793e-02,\n",
       "         -4.0042e-01, -1.0590e-01, -7.9196e-02, -5.3169e-02, -4.2956e-01,\n",
       "          2.4921e-01,  1.8581e-01, -5.3975e-01, -1.3230e-01, -1.8388e-01,\n",
       "         -3.3575e-01,  5.9694e-01,  2.5942e-01, -2.4107e-01,  6.6964e-01],\n",
       "        [-2.5452e-01, -1.8232e-01, -3.4223e-01, -5.3058e-01,  1.4869e-01,\n",
       "         -3.4410e-01, -3.0910e-01,  2.3679e-01, -3.6018e-02, -2.8454e-01,\n",
       "          4.4806e-01,  9.0095e-02, -5.2758e-01, -2.8383e-01, -2.8546e-01,\n",
       "         -4.6957e-01,  2.7713e-01,  6.0463e-02, -3.2539e-01,  4.8190e-01],\n",
       "        [-2.0027e-01, -1.9690e-01, -2.7976e-01, -5.5747e-01,  2.2334e-01,\n",
       "         -2.6755e-01, -3.9106e-01,  1.7591e-01, -2.6198e-02, -3.2246e-01,\n",
       "          4.0132e-01,  7.3884e-02, -5.4379e-01, -2.0250e-01, -1.1581e-01,\n",
       "         -3.9588e-01,  3.9154e-01,  1.8742e-01, -4.5382e-01,  4.6120e-01],\n",
       "        [-1.7053e-01, -2.6535e-01, -2.4105e-01, -5.2499e-01,  3.4071e-01,\n",
       "         -2.7362e-01, -3.6403e-01,  2.0413e-01,  3.6033e-02, -2.1302e-01,\n",
       "          3.4742e-01,  1.5160e-01, -5.3407e-01, -2.0895e-01, -1.2088e-01,\n",
       "         -4.3046e-01,  3.5575e-01,  1.8406e-01, -4.4683e-01,  5.1114e-01],\n",
       "        [-1.2716e-01, -1.9307e-01, -2.7769e-01, -5.2825e-01,  3.2261e-01,\n",
       "         -2.2888e-01, -3.4098e-01,  1.9997e-01,  4.2906e-02, -1.8463e-01,\n",
       "          3.7991e-01,  1.4883e-01, -5.4212e-01, -1.3934e-01, -1.1930e-01,\n",
       "         -4.4700e-01,  3.3293e-01,  1.4329e-01, -4.5800e-01,  5.0687e-01],\n",
       "        [-1.3530e-01, -2.1795e-01, -2.5667e-01, -5.4709e-01,  2.9584e-01,\n",
       "         -2.1705e-01, -3.6305e-01,  1.8044e-01, -2.5279e-03, -1.9520e-01,\n",
       "          3.7660e-01,  1.5466e-01, -5.1862e-01, -1.5682e-01, -8.4884e-02,\n",
       "         -4.4023e-01,  3.3402e-01,  1.4953e-01, -4.7400e-01,  4.8866e-01],\n",
       "        [-1.3198e-01, -2.3145e-01, -2.3023e-01, -5.4366e-01,  3.0767e-01,\n",
       "         -2.3576e-01, -3.5115e-01,  1.9110e-01, -1.8224e-04, -2.0361e-01,\n",
       "          3.6463e-01,  1.5746e-01, -5.1352e-01, -1.5195e-01, -7.7513e-02,\n",
       "         -4.3744e-01,  3.3510e-01,  1.4789e-01, -4.5809e-01,  4.9968e-01],\n",
       "        [-1.3683e-01, -2.2144e-01, -2.2947e-01, -5.4228e-01,  3.1895e-01,\n",
       "         -2.3152e-01, -3.4529e-01,  2.0465e-01,  8.0811e-03, -1.9879e-01,\n",
       "          3.6847e-01,  1.5912e-01, -5.1191e-01, -1.3571e-01, -8.1329e-02,\n",
       "         -4.3274e-01,  3.3163e-01,  1.4371e-01, -4.4845e-01,  5.0457e-01]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.contiguous().view(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:20:37.652343Z",
     "start_time": "2019-03-20T05:20:37.645549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3105,  0.1158,  0.0044, -0.4615,  0.1008, -0.2421,  0.0286,  0.7411,\n",
       "          0.0107, -0.1633],\n",
       "        [-0.1512,  0.1831,  0.2385, -0.3984,  0.1127,  0.0525,  0.1571,  0.2903,\n",
       "         -0.0915,  0.1583],\n",
       "        [-0.0670,  0.3136,  0.1289, -0.3910,  0.1442, -0.0404,  0.1840,  0.4297,\n",
       "          0.0207, -0.0770],\n",
       "        [-0.1334,  0.2560,  0.2183, -0.3924,  0.0808, -0.2097,  0.3281,  0.3611,\n",
       "         -0.0299,  0.0423],\n",
       "        [-0.0652,  0.2462,  0.1277, -0.3984,  0.0766, -0.0683,  0.2620,  0.3248,\n",
       "         -0.0660,  0.0603],\n",
       "        [-0.0482,  0.2495,  0.1304, -0.4210,  0.0695, -0.1330,  0.2947,  0.2934,\n",
       "         -0.0532,  0.0627],\n",
       "        [-0.0374,  0.2259,  0.1287, -0.4006,  0.0496, -0.1378,  0.2723,  0.2919,\n",
       "         -0.0412,  0.0624],\n",
       "        [-0.0409,  0.2273,  0.1239, -0.4033,  0.0518, -0.1155,  0.2629,  0.2886,\n",
       "         -0.0418,  0.0583],\n",
       "        [-0.0413,  0.2209,  0.1179, -0.4024,  0.0608, -0.1161,  0.2684,  0.2846,\n",
       "         -0.0406,  0.0620],\n",
       "        [-0.0384,  0.2164,  0.1166, -0.4000,  0.0594, -0.1202,  0.2726,  0.2783,\n",
       "         -0.0397,  0.0663]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = nn.Linear(20, 10)\n",
    "decoder(output.contiguous().view(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:57:15.493466Z",
     "start_time": "2019-03-21T20:57:15.486537Z"
    }
   },
   "outputs": [],
   "source": [
    "class DKT(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_skills, n_layers, dropout=0.6):\n",
    "        super(DKT, self).__init__()\n",
    "        nonlinearity = 'tanh'\n",
    "        self.rnn = nn.RNN(n_input, n_hidden, n_layers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(n_hidden, n_skills)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input, h0):\n",
    "        out, hn = self.rnn(input, h0)\n",
    "        decoded = self.decoder(out.contiguous().view(out.size(0) * out.size(1), out.size(2)))\n",
    "        decoded = self.sigmoid(decoded)\n",
    "        return decoded, hn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T12:11:26.237913Z",
     "start_time": "2019-03-20T12:11:26.234744Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size, n_input, n_hidden, n_skills, n_layers = 100, 11, 200, 124, 3\n",
    "model = DKT(n_input, n_hidden, n_skills, n_layers)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opt = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T12:14:40.586656Z",
     "start_time": "2019-03-20T12:14:40.555597Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 124]),\n",
       " torch.Size([3, 2, 200]),\n",
       " tensor([[0.6116, 0.4820, 0.5035,  ..., 0.6342, 0.5009, 0.4757],\n",
       "         [0.4488, 0.6189, 0.5894,  ..., 0.4676, 0.4545, 0.3915],\n",
       "         [0.5188, 0.5279, 0.4348,  ..., 0.5622, 0.5932, 0.5538],\n",
       "         ...,\n",
       "         [0.5104, 0.4528, 0.5390,  ..., 0.5472, 0.5325, 0.4887],\n",
       "         [0.5083, 0.4951, 0.5387,  ..., 0.4979, 0.5320, 0.5474],\n",
       "         [0.5366, 0.4896, 0.4657,  ..., 0.5006, 0.5350, 0.4768]],\n",
       "        grad_fn=<SigmoidBackward>),\n",
       " tensor([[[ 0.2260,  0.0347,  0.1071,  ...,  0.0734,  0.0432,  0.0282],\n",
       "          [ 0.2131, -0.0432,  0.1415,  ...,  0.1503, -0.0308, -0.1016]],\n",
       " \n",
       "         [[ 0.1415, -0.2512, -0.1896,  ..., -0.1539,  0.0097, -0.0489],\n",
       "          [ 0.3127,  0.3186, -0.1157,  ..., -0.2915,  0.0513,  0.0634]],\n",
       " \n",
       "         [[ 0.2399, -0.2789, -0.4127,  ..., -0.0190,  0.0545,  0.2523],\n",
       "          [ 0.2764,  0.2872, -0.0723,  ..., -0.0987, -0.1603,  0.1673]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2は可変長かな\n",
    "input = torch.randn(batch_size, 2, n_input)\n",
    "h0 = torch.randn(n_layers, 2, n_hidden)\n",
    "o, hn = model(input, h0)\n",
    "o.size(), hn.size(), o, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T10:23:47.287787Z",
     "start_time": "2019-03-20T10:23:45.327311Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    input = torch.randn(2000, 1, 10)\n",
    "    h0 = Variable(torch.zeros(2, 1, n_hidden))\n",
    "    target = torch.Tensor([np.eye(124)[64] for _ in range(2000)])\n",
    "    \n",
    "    out, hn = model(input, h0)\n",
    "    \n",
    "    loss = criterion(out, target)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T10:43:50.856079Z",
     "start_time": "2019-03-20T10:43:50.844407Z"
    }
   },
   "source": [
    "# 作っていくよー！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T12:05:27.652902Z",
     "start_time": "2019-03-20T12:05:27.382808Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.data import prepare_data\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:06:09.862014Z",
     "start_time": "2019-03-21T20:06:09.741503Z"
    }
   },
   "outputs": [],
   "source": [
    "data = prepare_data()\n",
    "M = 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T12:05:43.666829Z",
     "start_time": "2019-03-20T12:05:43.378479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14671a630>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([len(d) for d in data.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T08:34:26.475917Z",
     "start_time": "2019-03-24T08:34:24.021314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3884, 30, 249]) torch.Size([3884, 249])\n",
      "torch.Size([3884, 124]) torch.Size([3884])\n",
      "3107 777\n"
     ]
    }
   ],
   "source": [
    "min_n, max_n = 3, 30\n",
    "sequence_size = 30\n",
    "\n",
    "N = ceil(log(2 * M))\n",
    "\n",
    "def qaToIdxNum(q_and_a: Tuple) -> int:\n",
    "    return q_and_a[0] + q_and_a[1] * M + 1  # consider 0\n",
    "\n",
    "def idxToOneHot(idxnum: int):  # idxnum should already considered 0\n",
    "    onehot = np.zeros(2*M + 1)  # consider 0\n",
    "    onehot[idxnum] = 1\n",
    "    return onehot\n",
    "\n",
    "def qaToOnehot(q_and_a: Tuple):\n",
    "    idx = qaToIdxNum(q_and_a)\n",
    "    onehot = idxToOneHot(idx)\n",
    "    return onehot\n",
    "\n",
    "def sequenceToOnehot(sequence_qa: List):\n",
    "    length = len(sequence_qa)\n",
    "    sequence = list(map(qaToIdxNum, sequence_qa)) + [0] * (sequence_size - length)\n",
    "    onehotSeq = list(map(idxToOneHot, sequence))\n",
    "    return onehotSeq\n",
    "\n",
    "def qaToOnehotQandA(qa: Tuple):\n",
    "    onehot_q = np.zeros(M)\n",
    "    onehot_q[qa[0]] = 1\n",
    "    a = qa[1]\n",
    "    return onehot_q, a\n",
    "\n",
    "\n",
    "x_values = []\n",
    "y_values = []\n",
    "x_onehot = []\n",
    "y_onehot = []\n",
    "y_onehot_q = []\n",
    "y_onehot_a = []\n",
    "for d in data.values():\n",
    "    if max_n < len(d): # max_n + 1 以上の長さから、最後をy、それまでで最後のmax_nをxとする\n",
    "        x_values.append(d[-1-max_n:-1])\n",
    "        y_values.append(d[-1])\n",
    "        x_onehot.append(sequenceToOnehot(d[-1-max_n:-1]))\n",
    "        y_onehot.append(qaToOnehot(d[-1]))\n",
    "        ohq, a = qaToOnehotQandA(d[-1])\n",
    "        y_onehot_q.append(ohq)\n",
    "        y_onehot_a.append(a)\n",
    "    elif min_n <= len(d) <= max_n:\n",
    "        x_values.append(d[:-1])\n",
    "        y_values.append(d[-1])\n",
    "        x_onehot.append(sequenceToOnehot(d[-1-max_n:-1]))\n",
    "        y_onehot.append(qaToOnehot(d[-1]))\n",
    "        ohq, a = qaToOnehotQandA(d[-1])\n",
    "        y_onehot_q.append(ohq)\n",
    "        y_onehot_a.append(a)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "x_tensor, y_tensor = torch.Tensor(x_onehot), torch.Tensor(y_onehot)\n",
    "print(x_tensor.size(), y_tensor.size())\n",
    "y_tensor_q, y_tensor_a = torch.Tensor(y_onehot_q), torch.Tensor(y_onehot_a)\n",
    "print(y_tensor_q.size(), y_tensor_a.size())\n",
    "all_ds = TensorDataset(x_tensor, y_tensor_q, y_tensor_a)\n",
    "\n",
    "train_num = int(len(all_ds) * .8)\n",
    "train_ds, eval_ds = random_split(all_ds, [train_num, len(all_ds) - train_num])\n",
    "print(len(train_ds), len(eval_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:52:10.410501Z",
     "start_time": "2019-03-23T22:52:10.399436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1.],\n",
       "         [0., 0., 3.],\n",
       "         [0., 0., 5.],\n",
       "         [0., 0., 7.]],\n",
       "\n",
       "        [[0., 2., 0.],\n",
       "         [0., 4., 0.],\n",
       "         [0., 6., 0.],\n",
       "         [0., 8., 0.]]])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.Tensor(\n",
    "[\n",
    "    [[0,0,1], [0,2,0]],\n",
    "    [[0,0,3], [0,4,0]],\n",
    "    [[0,0,5], [0,6,0]],\n",
    "    [[0,0,7], [0,8,0]]\n",
    "]\n",
    ")\n",
    "print(tmp.size())\n",
    "tmp.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T09:58:21.269820Z",
     "start_time": "2019-03-24T09:57:59.516301Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qiushi/packages/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6640, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6365, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.6050, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "0.5857543578441194\n"
     ]
    }
   ],
   "source": [
    "class DKT(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output, n_layers, dropout=0.6):\n",
    "        super(DKT, self).__init__()\n",
    "        nonlinearity = 'tanh'\n",
    "        # https://pytorch.org/docs/stable/nn.html#rnn\n",
    "        self.rnn = nn.RNN(n_input, n_hidden, n_layers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(n_hidden, n_output)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, input, h0):\n",
    "        out, hn = self.rnn(input, h0)\n",
    "        # top_n, top_i = out.topk(1)\n",
    "        # decoded = self.decoder(out.contiguous().view(out.size(0) * out.size(1), out.size(2)))\n",
    "        out = self.decoder(out)\n",
    "        # decoded = self.sigmoid(decoded)\n",
    "    \n",
    "        return out, hn\n",
    "    \n",
    "\n",
    "batch_size, n_input, n_hidden, n_skills, n_layers = 100, N, 200, 124, 1\n",
    "n_output = n_skills\n",
    "onehot_size = n_skills * 2 + 1\n",
    "# n_input = onehot_size  #\n",
    "all_dl = DataLoader(all_ds, batch_size=batch_size, drop_last=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, drop_last=True)\n",
    "eval_dl = DataLoader(eval_ds, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "model = DKT(n_input, n_hidden, n_output, n_layers)\n",
    "# model  = nn.RNN(n_input, n_hidden, n_layers, nonlinearity='tanh', dropout=0.6)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opt = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 501):  # epochは全体を回す処理\n",
    "    model.train()\n",
    "    for xs, yq, ya in train_dl:\n",
    "        input = xs\n",
    "        compressed_sensing = True\n",
    "        if compressed_sensing and onehot_size != n_input:\n",
    "            torch.manual_seed(0)\n",
    "            cs_basis = torch.randn(onehot_size, n_input)\n",
    "            input = torch.mm(input.contiguous().view(-1, onehot_size), cs_basis)\n",
    "            # https://pytorch.org/docs/stable/nn.html?highlight=rnn#rnn\n",
    "            # inputの説明を見ると、input of shape (seq_len, batch, input_size)　とある\n",
    "            input = input.view(batch_size, sequence_size, n_input)\n",
    "        input = input.permute(1, 0, 2)\n",
    "\n",
    "        h0 = torch.zeros(n_layers, batch_size, n_hidden)\n",
    "        target = ya\n",
    "\n",
    "        out, hn = model(input, h0)\n",
    "\n",
    "        # logits = torch.gather(output, 0, target_id)\n",
    "\n",
    "        pred = torch.sigmoid(out[-1])  # [0, 1]区間にする\n",
    "        prob = torch.max(pred * yq, 1)[0]\n",
    "        loss = criterion(prob, target)  # TODO: 最後の1個だけじゃなくて、その他も損失関数に利用したら？\n",
    "        if epoch % 100 == 0:\n",
    "            print(loss)\n",
    "    \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        break\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            val_prob = []\n",
    "            val_targ = []\n",
    "            for xs, yq, ya in eval_dl:\n",
    "                input = xs\n",
    "                if compressed_sensing:\n",
    "                    torch.manual_seed(0)\n",
    "                    cs_basis = torch.randn(onehot_size, n_input)\n",
    "                    input = torch.mm(input.contiguous().view(-1, onehot_size), cs_basis)\n",
    "                    # https://pytorch.org/docs/stable/nn.html?highlight=rnn#rnn\n",
    "                    # inputの説明を見ると、input of shape (seq_len, batch, input_size)　とある\n",
    "                    input = input.view(batch_size, sequence_size, n_input)\n",
    "                input = input.permute(1, 0, 2)\n",
    "                target = ya\n",
    "                h0 = torch.zeros(n_layers, batch_size, n_hidden)\n",
    "                out, hn = model(input, h0)\n",
    "                pred = torch.sigmoid(out[-1])  # [0, 1]区間にする\n",
    "                prob = torch.max(pred * yq, 1)[0]\n",
    "                loss = criterion(prob, target)\n",
    "                \n",
    "                val_prob.append(prob)\n",
    "                val_targ.append(target)\n",
    "                \n",
    "            y = torch.cat(val_targ)\n",
    "            pred = torch.cat(val_prob)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "            print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-de191f53719d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:03:13.558339Z",
     "start_time": "2019-03-23T22:03:13.552615Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4689)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(out[0][-1][80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:08:46.430868Z",
     "start_time": "2019-03-23T22:08:46.423769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(80))"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[-1].max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T10:08:30.480185Z",
     "start_time": "2019-03-22T10:08:30.411046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 248])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1278,  0.0492,  0.0696,  ..., -0.0495,  0.1539, -0.1486]],\n",
       " \n",
       "         [[-0.0380, -0.0167, -0.0010,  ..., -0.1320,  0.1119, -0.2290]],\n",
       " \n",
       "         [[ 0.1597, -0.1223, -0.2632,  ..., -0.0651,  0.1030, -0.2331]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.2434,  0.0246, -0.0651,  ..., -0.0814,  0.0284,  0.0096]],\n",
       " \n",
       "         [[ 0.2554,  0.0215, -0.1880,  ..., -0.0730,  0.1586, -0.1213]],\n",
       " \n",
       "         [[ 0.2074,  0.0412, -0.1263,  ...,  0.0578,  0.2029, -0.2085]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 2.0741e-01,  4.1194e-02, -1.2627e-01,  9.5058e-02,  5.9134e-02,\n",
       "            1.6616e-04,  1.1978e-01,  6.9009e-02,  1.3488e-01, -1.3914e-01,\n",
       "           -4.0156e-02,  1.5901e-01,  3.0396e-02,  1.2145e-01,  5.9034e-02,\n",
       "            7.5554e-02, -8.9835e-02,  2.1130e-01,  2.6609e-02, -3.4190e-02,\n",
       "            1.1141e-01, -1.1124e-01, -2.5882e-02,  3.1236e-02, -1.1198e-02,\n",
       "            2.6103e-01, -9.9711e-02,  8.6882e-02, -1.6155e-01,  2.2450e-02,\n",
       "            1.1042e-01,  7.8981e-02,  1.1196e-01,  4.7710e-02,  5.9331e-02,\n",
       "            3.3257e-02, -1.1537e-02,  2.2966e-02,  7.5620e-02, -1.5772e-01,\n",
       "            6.9920e-02, -7.0070e-02,  1.9381e-03, -9.7523e-04, -5.8321e-02,\n",
       "           -3.8006e-02,  1.4312e-01, -5.8207e-02,  4.4674e-02,  9.6930e-03,\n",
       "           -5.9863e-02, -8.1158e-02, -1.6142e-02, -4.3842e-02,  7.7079e-02,\n",
       "           -5.9818e-02, -4.1338e-02, -8.6248e-02,  4.9940e-02,  1.1428e-02,\n",
       "            3.3553e-02,  5.4133e-02,  1.3598e-01, -1.5880e-02, -3.7855e-02,\n",
       "            3.4884e-02, -1.0778e-01,  2.3776e-01,  2.1222e-01,  1.0383e-02,\n",
       "            6.4383e-02, -1.2658e-01,  6.3879e-02, -4.8112e-02,  2.3443e-01,\n",
       "            1.1366e-01,  2.3552e-01,  7.9976e-02,  9.5836e-02,  4.8502e-02,\n",
       "           -8.4069e-02,  6.9152e-02, -4.2358e-02, -1.0025e-01, -1.9073e-01,\n",
       "            6.0463e-02,  4.5193e-02,  8.8574e-02, -1.3808e-02, -2.3905e-01,\n",
       "           -1.9714e-01,  6.6799e-02,  1.1870e-01,  7.2644e-02, -9.2118e-02,\n",
       "           -2.1402e-01,  8.0103e-03, -2.1429e-02, -8.8344e-02,  7.3335e-02,\n",
       "           -2.5631e-01,  1.2720e-02, -1.8200e-01, -1.9647e-01,  3.6060e-02,\n",
       "           -2.1342e-02, -1.0003e-02,  4.8487e-02,  5.6842e-02, -5.8994e-02,\n",
       "           -7.7926e-02,  1.0444e-01, -2.5138e-01,  1.0168e-01, -4.7552e-02,\n",
       "            4.4779e-02,  2.4673e-02,  2.8600e-03,  1.2401e-01,  1.9144e-01,\n",
       "            1.0653e-01,  1.6755e-01,  1.1733e-02, -1.0932e-02,  2.1786e-02,\n",
       "           -4.6672e-02,  1.7769e-02, -8.9152e-02,  7.7011e-02, -2.9201e-02,\n",
       "           -1.1027e-01,  2.1370e-01,  5.3365e-02, -1.8956e-02, -1.8114e-02,\n",
       "           -1.6134e-01,  9.4391e-02,  1.7149e-01, -1.2606e-01,  8.3602e-02,\n",
       "            8.3271e-02,  1.4165e-01, -1.0376e-01, -1.9475e-01,  6.4878e-02,\n",
       "           -1.7177e-02, -1.5177e-01,  4.1964e-02, -6.4559e-02, -3.9038e-02,\n",
       "            1.8161e-01, -8.2693e-02, -2.7257e-01, -1.6837e-01,  2.1382e-01,\n",
       "           -2.7955e-01, -6.6496e-02,  8.9116e-02, -1.1907e-01, -1.4284e-02,\n",
       "            9.0312e-02, -2.8140e-01, -2.0978e-02, -2.5823e-02,  1.8803e-01,\n",
       "            1.1028e-01, -1.1931e-01,  1.4644e-01, -1.2865e-01,  2.8511e-02,\n",
       "           -6.0585e-02,  5.7296e-02,  1.2685e-01, -3.1833e-02, -4.4361e-02,\n",
       "            1.0029e-01, -4.3760e-02,  3.9050e-02,  2.4859e-01, -1.3810e-01,\n",
       "            8.4701e-02, -6.2848e-02,  7.1192e-03,  3.7309e-02,  1.3697e-01,\n",
       "           -1.3111e-01,  9.9701e-02,  1.2873e-01,  1.2599e-01,  8.4733e-02,\n",
       "           -4.0115e-02,  1.4609e-01, -3.6564e-02,  2.0571e-01,  7.2297e-02,\n",
       "           -1.0668e-01, -9.0598e-02,  5.7758e-02,  2.0292e-01, -2.0852e-01]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix = torch.randn(n_skills * 2, n_input)\n",
    "input = torch.mm(torch.Tensor(x_onehot[0:1]).contiguous().view(-1, 248), random_matrix)\n",
    "print(torch.Tensor(x_onehot[0:1]).size())\n",
    "input = input.view(30, 1, 6)\n",
    "h0 = torch.zeros(n_layers, 1, n_hidden)\n",
    "\n",
    "model = nn.RNN(n_input, n_hidden, n_layers, nonlinearity='tanh', dropout=0.6)\n",
    "model(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T06:15:41.569928Z",
     "start_time": "2019-03-22T06:15:41.561246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 248])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(x_onehot[0:2]).contiguous().view(-1, 248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 調整してくよー！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "import os\n",
    "from math import log, ceil\n",
    "from typing import List, Tuple, Set, Dict\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from src.data import prepare_data\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PyTorch version\n",
    "# =========================\n",
    "print('PyTorch:', torch.__version__)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Parameters\n",
    "# =========================\n",
    "lr = 0.01\n",
    "batch_size, n_hidden, n_skills, n_layers = 100, 200, 124, 1\n",
    "n_output = n_skills\n",
    "onehot_size = n_skills * 2 + 1\n",
    "n_input = ceil(log(2 * n_skills))\n",
    "# n_input = onehot_size  #\n",
    "\n",
    "# =========================\n",
    "# Data\n",
    "# =========================\n",
    "data = prepare_data()\n",
    "M = n_skills\n",
    "min_n, max_n = 3, 30\n",
    "sequence_size = 30\n",
    "\n",
    "N = ceil(log(2 * M))\n",
    "\n",
    "\n",
    "def qaToIdxNum(q_and_a: Tuple) -> int:\n",
    "    return q_and_a[0] + q_and_a[1] * M + 1  # consider 0\n",
    "\n",
    "\n",
    "def idxToOneHot(idxnum: int):  # idxnum should already considered 0\n",
    "    onehot = np.zeros(2 * M + 1)  # consider 0\n",
    "    onehot[idxnum] = 1\n",
    "    return onehot\n",
    "\n",
    "\n",
    "def qaToOnehot(q_and_a: Tuple):\n",
    "    idx = qaToIdxNum(q_and_a)\n",
    "    onehot = idxToOneHot(idx)\n",
    "    return onehot\n",
    "\n",
    "\n",
    "def sequenceToOnehot(sequence_qa: List):\n",
    "    length = len(sequence_qa)\n",
    "    sequence = list(map(qaToIdxNum, sequence_qa)) + \\\n",
    "        [0] * (sequence_size - length)\n",
    "    onehotSeq = list(map(idxToOneHot, sequence))\n",
    "    return onehotSeq\n",
    "\n",
    "\n",
    "def qaToOnehotQandA(qa: Tuple):\n",
    "    onehot_q = np.zeros(M)\n",
    "    onehot_q[qa[0]] = 1\n",
    "    a = qa[1]\n",
    "    return onehot_q, a\n",
    "\n",
    "\n",
    "x_values = []\n",
    "y_values = []\n",
    "x_onehot = []\n",
    "y_onehot = []\n",
    "y_onehot_q = []\n",
    "y_onehot_a = []\n",
    "for d in data.values():\n",
    "    if max_n < len(d):  # max_n + 1 以上の長さから、最後をy、それまでで最後のmax_nをxとする\n",
    "        x_values.append(d[-1 - max_n:-1])\n",
    "        y_values.append(d[-1])\n",
    "        x_onehot.append(sequenceToOnehot(d[-1 - max_n:-1]))\n",
    "        y_onehot.append(qaToOnehot(d[-1]))\n",
    "        ohq, a = qaToOnehotQandA(d[-1])\n",
    "        y_onehot_q.append(ohq)\n",
    "        y_onehot_a.append(a)\n",
    "    elif min_n <= len(d) <= max_n:\n",
    "        x_values.append(d[:-1])\n",
    "        y_values.append(d[-1])\n",
    "        x_onehot.append(sequenceToOnehot(d[-1 - max_n:-1]))\n",
    "        y_onehot.append(qaToOnehot(d[-1]))\n",
    "        ohq, a = qaToOnehotQandA(d[-1])\n",
    "        y_onehot_q.append(ohq)\n",
    "        y_onehot_a.append(a)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "x_tensor, y_tensor = torch.Tensor(x_onehot), torch.Tensor(y_onehot)\n",
    "y_tensor_q, y_tensor_a = torch.Tensor(y_onehot_q), torch.Tensor(y_onehot_a)\n",
    "all_ds = TensorDataset(x_tensor, y_tensor_q, y_tensor_a)\n",
    "train_num = int(len(all_ds) * .8)\n",
    "train_ds, eval_ds = random_split(all_ds, [train_num, len(all_ds) - train_num])\n",
    "\n",
    "all_dl = DataLoader(all_ds, batch_size=batch_size, drop_last=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, drop_last=True)\n",
    "eval_dl = DataLoader(eval_ds, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "# =========================\n",
    "# Model\n",
    "# =========================\n",
    "\n",
    "\n",
    "class DKT(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output, n_layers, dropout=0.6):\n",
    "        super(DKT, self).__init__()\n",
    "        nonlinearity = 'tanh'\n",
    "        # https://pytorch.org/docs/stable/nn.html#rnn\n",
    "        self.rnn = nn.RNN(n_input, n_hidden, n_layers,\n",
    "                          nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(n_hidden, n_output)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input, h0):\n",
    "        out, hn = self.rnn(input, h0)\n",
    "        # top_n, top_i = out.topk(1)\n",
    "        # decoded = self.decoder(out.contiguous().view(out.size(0) * out.size(1), out.size(2)))\n",
    "        out = self.decoder(out)\n",
    "        # decoded = self.sigmoid(decoded)\n",
    "\n",
    "        return out, hn\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Prepare and Train\n",
    "# =========================\n",
    "loss_func = nn.BCELoss()\n",
    "model = DKT(n_input, n_hidden, n_output, n_layers)\n",
    "criterion = nn.BCELoss()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(1, 2001):  # epochは全体を回す処理\n",
    "    model.train()\n",
    "    for xs, yq, ya in train_dl:\n",
    "        input = xs\n",
    "        compressed_sensing = True\n",
    "        if compressed_sensing and onehot_size != n_input:\n",
    "            torch.manual_seed(0)\n",
    "            cs_basis = torch.randn(onehot_size, n_input)\n",
    "            input = torch.mm(\n",
    "                input.contiguous().view(-1, onehot_size), cs_basis)\n",
    "            # https://pytorch.org/docs/stable/nn.html?highlight=rnn#rnn\n",
    "            # inputの説明を見ると、input of shape (seq_len, batch, input_size)　とある\n",
    "            input = input.view(batch_size, sequence_size, n_input)\n",
    "        input = input.permute(1, 0, 2)\n",
    "\n",
    "        h0 = torch.zeros(n_layers, batch_size, n_hidden)\n",
    "        target = ya\n",
    "\n",
    "        out, hn = model(input, h0)\n",
    "\n",
    "        # logits = torch.gather(output, 0, target_id)\n",
    "\n",
    "        pred = torch.sigmoid(out[-1])  # [0, 1]区間にする\n",
    "        prob = torch.max(pred * yq, 1)[0]\n",
    "        loss = criterion(prob, target)  # TODO: 最後の1個だけじゃなくて、その他も損失関数に利用したら？\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch:', epoch, 'Loss:', loss)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for xs, yq, ya in eval_dl:\n",
    "                input = xs\n",
    "                if compressed_sensing:\n",
    "                    torch.manual_seed(0)\n",
    "                    cs_basis = torch.randn(onehot_size, n_input)\n",
    "                    input = torch.mm(\n",
    "                        input.contiguous().view(-1, onehot_size), cs_basis)\n",
    "                    # https://pytorch.org/docs/stable/nn.html?highlight=rnn#rnn\n",
    "                    # inputの説明を見ると、input of shape (seq_len, batch, input_size)　とある\n",
    "                    input = input.view(batch_size, sequence_size, n_input)\n",
    "                input = input.permute(1, 0, 2)\n",
    "                target = ya\n",
    "                h0 = torch.zeros(n_layers, batch_size, n_hidden)\n",
    "                out, hn = model(input, h0)\n",
    "                pred = torch.sigmoid(out[-1])  # [0, 1]区間にする\n",
    "                prob = torch.max(pred * yq, 1)[0]\n",
    "                loss = criterion(prob, target)\n",
    "                print('EVAL Epoch:', epoch, 'Loss:', loss)\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            val_prob = []\n",
    "            val_targ = []\n",
    "            for xs, yq, ya in eval_dl:\n",
    "                input = xs\n",
    "                if compressed_sensing:\n",
    "                    torch.manual_seed(0)\n",
    "                    cs_basis = torch.randn(onehot_size, n_input)\n",
    "                    input = torch.mm(\n",
    "                        input.contiguous().view(-1, onehot_size), cs_basis)\n",
    "                    # https://pytorch.org/docs/stable/nn.html?highlight=rnn#rnn\n",
    "                    # inputの説明を見ると、input of shape (seq_len, batch, input_size)　とある\n",
    "                    input = input.view(batch_size, sequence_size, n_input)\n",
    "                input = input.permute(1, 0, 2)\n",
    "                target = ya\n",
    "                h0 = torch.zeros(n_layers, batch_size, n_hidden)\n",
    "                out, hn = model(input, h0)\n",
    "                pred = torch.sigmoid(out[-1])  # [0, 1]区間にする\n",
    "                prob = torch.max(pred * yq, 1)[0]\n",
    "                loss = criterion(prob, target)\n",
    "\n",
    "                val_prob.append(prob)\n",
    "                val_targ.append(target)\n",
    "\n",
    "            y = torch.cat(val_targ)\n",
    "            pred = torch.cat(val_prob)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "            print(metrics.auc(fpr, tpr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
